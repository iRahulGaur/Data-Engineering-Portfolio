<img src="https://github.com/iRahulGaur/Data-Engineering-Portfolio/blob/main/data_image.png" alt="Data image" width="700"/>

# Data Engineering Portfolio

Welcome to my **Data Engineering Portfolio**! This repository consolidates my work on data pipelines, orchestration, and cloud-based data solutions using **Apache Airflow, Snowflake, and dbt**. It serves as a showcase of my technical skills in designing and implementing scalable data engineering solutions.

## Projects

### 1. Airflow Data Pipeline
**Repository:** [airflow_project](https://github.com/iRahulGaur/airflow_project)

#### Overview
This project demonstrates the use of **Apache Airflow** for orchestrating ETL workflows. It automates the extraction, transformation, and loading of data from various sources into a target database.

#### Key Features
- **DAG (Directed Acyclic Graph) Scheduling**: Configured Airflow DAGs to automate and schedule data pipelines.
- **Task Dependencies**: Implemented task dependencies to ensure proper execution order.
- **Data Extraction & Transformation**: Utilized Python operators to fetch and process data before loading it into the database.
- **Monitoring & Logging**: Enabled Airflow logging and alerting mechanisms for pipeline health monitoring.

#### Tech Stack
- **Apache Airflow** for workflow orchestration
- **Python** for data extraction and transformation
- **PostgreSQL** as the data warehouse
- **Docker** for containerization

---

### 2. Snowflake & dbt Data Pipeline
**Repository:** [Data-pipeline-snowflake-dbt](https://github.com/iRahulGaur/Data-pipeline-snowflake-dbt)

#### Overview
This project showcases a modern cloud-based data pipeline using **Snowflake** and **dbt (Data Build Tool)** for efficient data transformation and modeling.

#### Key Features
- **Snowflake as Data Warehouse**: Used Snowflake to store and process large datasets efficiently.
- **dbt for Data Transformation**: Created modular and reusable SQL models for transforming raw data.
- **Incremental Data Processing**: Configured dbt models to perform incremental transformations, optimizing query performance.
- **CI/CD Integration**: Implemented a CI/CD workflow for dbt model testing and deployment.

#### Tech Stack
- **Snowflake** as a cloud data warehouse
- **dbt** for SQL-based transformations
- **Python** for scripting and automation
- **GitHub Actions** for CI/CD pipeline automation

---

### 3. NLP TF-IDF Preprocessing & Visualization
**Repository:** [NLP-TF-IDF](https://github.com/iRahulGaur/NLP-TF-IDF)

#### Overview
This project implements **Natural Language Processing (NLP) techniques** to preprocess text data and visualize word importance using **TF-IDF**. It includes:
- **Tokenization, Lemmatization, Stopword Removal**
- **TF-IDF Vectorization & Visualization**
- **Heatmaps, PCA Scatter Plots, and Word Clouds**
- **Python-based Jupyter Notebook Implementation**

#### Tech Stack
- **Python** for NLP processing
- **NLTK** for text preprocessing
- **Scikit-learn** for TF-IDF vectorization
- **Matplotlib & Seaborn** for visualization
- **WordCloud** for word cloud generation

#### Example Visualization:
![TF-IDF Word Cloud](https://github.com/iRahulGaur/NLP-TF-IDF/blob/main/screenshot.png?raw=true)

---

## Contact
Feel free to connect with me on **[LinkedIn](https://www.linkedin.com/in/irahulgaur)** or reach out via email at **rahul.gaur152@gmail.com** for any queries or collaboration opportunities.

### ðŸš€ Happy Coding!
